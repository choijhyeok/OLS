# OLS, VIF 가장 좋은 변수 찾기

&nbsp;

## 1. 목적 및 동기

 - 기존의 OLS 만으로 변수를 선택할 때 다중공선성의 위험이 존재 
 - OLS를 하면서 VIF까지 자동으로 수행하도록 하면 더 편하게 좋은 변수를 결정할 수 있다고 생각함
 - OLS 사용법과, VIF 사용법을 조금 더 확실하게 이해하기 위해 수행
 
&nbsp;

## 2. 데이터
 - Vehicle dataset : https://ijeremiah.com/portfolio/cars/
    - 중고차 데이터 셋


&nbsp;
## 3. OLS 란?

 - 잔차제곱합을 최소화하는 가중치 벡터를 구하는 방법
 - OLS 사용하면 독립변수 x에 대해 종속변수 y에 영향이 있는지 확인가능 , 또한 P-value도 확인가능
 - 회귀 방정식을 구할 수 있고, 각각의 계수를 확인할 수 있음
 
&nbsp;
## 4. VIF란?

 - OLS를 통해 독립-종속이 유의한 변수를 골라도 각각의 변수는 독립-독립 간의 상관관계는 있으면 안됨
 - 독립-독립 간의 상관관계를 보이는 것이 다중 공산성, 다중공산성이 존재할 때 부정확한 회귀 결과가 도출됨
   - 다중공산성을 파악하는 방법
     1. 산점도 그래
     2. VIF 
     
      2가지다 다중 공산성을 확인할 수 있는 방법이지만 그래프는 눈으로 확인해야 하므로 여기에서는 VIF를 사용
     
&nbsp;
## 5. 최종적 목표

 - OLS를 통해서 P-value 0.05 이하인 변수를 찾음
 - 각 과정마다 P-value 0.05 이상의 변수는 제거
 - 제거 후에 VIF &amp;gt;10인 변수 찾아서 제거 
 
 :zap: 위 과정을 검출 안될 때까지 자동으로 학습해서 결과적으로 최적의 변수 선택
 
 
&nbsp;
## 6. 결측치

 - 많은 데이터 분석을 수행할 때 결측치에 대한 방법은 개개인의 판단으로 여겨지는 경우가 많음
 - 해당 데이터의 도메인 지식이 많으면 개인이 판단하에 데이터를 삽입할 수 있고 대부분은 데이터 결측이 있는 행 자체를 날림
 - 이번의  Vehicle dataset을 통한 데이터 전처리 시에 결측치를 3가지 방법으로 다뤄보면서 수행할 예정
     1. dropna 방식 = 결측 행 전체를 날리는 방식
     2. simpleimputer 방식 = 결측의 행을 그 열의 평균으로 대체하는 방뻐
     3. IterativeImputer 방식
         - 참고논문 : https://www.jstatsoft.org/article/view/v045i03
         - 사용 가능한 특성 차원의 전체 세트를 사용해서 누락 된 값을 추정
         
         :repeat: IterativeImputer 과정
         
            1. 누락된 값이 있는 각 열을 다른 열의 값으로 모델링하고 해당 추정치를 대치에 사용
            2. 각 단계에서 특성 열은 출력 y로 지정되고 다른 특성 열은 입력 X로 처리
            3. 회귀 변수는 알려진 y 에 대해 (X, y) 에 적합
            4. 그런 다음 회귀 변수를 사용하여 y의 결측값을 예측
            5. 각 기능에 대해 반복적인 방식으로 수행된 다음 max_iter 만큼 반복됩니다
            6. 최종 라운드에 결과가 반환됩니다.
            
         :question: IterativeImputer 문제점
         
            - 아직 실험적인 방법
            - 실질적으로 사용방법에 k-fold와 같은 검증을 거치고 사용해야 위험이 줄어들고
            - 제대로 사용하기에는 다양한 사용자의 판단이 필요
